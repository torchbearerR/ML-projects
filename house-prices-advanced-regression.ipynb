{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===============================================================\n# 1. IMPORT LIBRARIES\n# ===============================================================\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet\nfrom sklearn.ensemble import StackingRegressor, RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ===============================================================\n# 2. LOAD DATA\n# ===============================================================\ntrain = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n\nprint(train.shape, test.shape)\ntrain.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T12:03:27.500431Z","iopub.execute_input":"2025-11-16T12:03:27.501280Z","iopub.status.idle":"2025-11-16T12:03:28.692655Z","shell.execute_reply.started":"2025-11-16T12:03:27.501240Z","shell.execute_reply":"2025-11-16T12:03:28.691875Z"}},"outputs":[{"name":"stdout","text":"(1460, 81) (1459, 80)\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n\n  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n\n  YrSold  SaleType  SaleCondition  SalePrice  \n0   2008        WD         Normal     208500  \n1   2007        WD         Normal     181500  \n2   2008        WD         Normal     223500  \n3   2006        WD        Abnorml     140000  \n4   2008        WD         Normal     250000  \n\n[5 rows x 81 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 81 columns</p>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# ===============================================================\n# 3. REMOVE OUTLIERS (optional but improves CV)\n# Example: remove houses with too large GrLivArea but low price\n# ===============================================================\ntrain = train[train['GrLivArea'] < 4500]\n\n# Reset index after filtering\ntrain.reset_index(drop=True, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T12:03:35.561496Z","iopub.execute_input":"2025-11-16T12:03:35.562297Z","iopub.status.idle":"2025-11-16T12:03:35.569188Z","shell.execute_reply.started":"2025-11-16T12:03:35.562268Z","shell.execute_reply":"2025-11-16T12:03:35.568287Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ===============================================================\n# 4. TARGET VARIABLE\n# Log-transform to fix skew\n# ===============================================================\ny = np.log1p(train['SalePrice'])\n\n# Drop ID and target\ntrain.drop(['SalePrice', 'Id'], axis=1, inplace=True)\ntest_ids = test['Id']\ntest.drop(['Id'], axis=1, inplace=True)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T12:03:41.677600Z","iopub.execute_input":"2025-11-16T12:03:41.677987Z","iopub.status.idle":"2025-11-16T12:03:41.687102Z","shell.execute_reply.started":"2025-11-16T12:03:41.677964Z","shell.execute_reply":"2025-11-16T12:03:41.686238Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ===============================================================\n# 5. COMBINE TRAIN + TEST FOR CONSISTENT PREPROCESSING\n# ===============================================================\nfull = pd.concat([train, test], axis=0)\n\n# Identify numeric & categorical columns\nnumeric_features = full.select_dtypes(include=[np.number]).columns\ncategorical_features = full.select_dtypes(include=['object']).columns\n\nprint(\"Numeric:\", len(numeric_features), \"Categorical:\", len(categorical_features))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T12:04:04.551363Z","iopub.execute_input":"2025-11-16T12:04:04.551725Z","iopub.status.idle":"2025-11-16T12:04:04.569706Z","shell.execute_reply.started":"2025-11-16T12:04:04.551698Z","shell.execute_reply":"2025-11-16T12:04:04.568713Z"}},"outputs":[{"name":"stdout","text":"Numeric: 36 Categorical: 43\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ===============================================================\n# 6. HANDLE MISSING VALUES\n# - numeric: fill with median\n# - categorical: fill with mode\n# ===============================================================\nfor col in numeric_features:\n    full[col].fillna(full[col].median(), inplace=True)\n\nfor col in categorical_features:\n    full[col].fillna(full[col].mode()[0], inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T12:04:29.202155Z","iopub.execute_input":"2025-11-16T12:04:29.202517Z","iopub.status.idle":"2025-11-16T12:04:29.251474Z","shell.execute_reply.started":"2025-11-16T12:04:29.202488Z","shell.execute_reply":"2025-11-16T12:04:29.250583Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ===============================================================\n# 7. ONE-HOT ENCODING\n# ===============================================================\nfull = pd.get_dummies(full, drop_first=True)\n\n# Split back to train/test\nX = full[:len(y)]\nX_test = full[len(y):]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T12:04:44.301189Z","iopub.execute_input":"2025-11-16T12:04:44.302191Z","iopub.status.idle":"2025-11-16T12:04:44.352523Z","shell.execute_reply.started":"2025-11-16T12:04:44.302147Z","shell.execute_reply":"2025-11-16T12:04:44.351565Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ===============================================================\n# 8. STANDARDIZATION\n# ===============================================================\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_test_scaled = scaler.transform(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T12:05:04.626149Z","iopub.execute_input":"2025-11-16T12:05:04.626518Z","iopub.status.idle":"2025-11-16T12:05:04.700954Z","shell.execute_reply.started":"2025-11-16T12:05:04.626490Z","shell.execute_reply":"2025-11-16T12:05:04.699976Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ===============================================================\n# 9. DEFINE MODELS\n# ===============================================================\nlasso = Lasso(alpha=0.0005, max_iter=50000)\nridge = Ridge(alpha=10)\nelastic = ElasticNet(alpha=0.0005, l1_ratio=0.5)\n\n# STACKING MODEL (base models + meta model)\nestimators = [\n    ('ridge', ridge),\n    ('lasso', lasso),\n    ('elastic', elastic)\n]\n\nstack_model = StackingRegressor(\n    estimators=estimators,\n    final_estimator=RandomForestRegressor(n_estimators=300, random_state=42),\n    passthrough=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T12:05:23.072958Z","iopub.execute_input":"2025-11-16T12:05:23.073294Z","iopub.status.idle":"2025-11-16T12:05:23.079707Z","shell.execute_reply.started":"2025-11-16T12:05:23.073267Z","shell.execute_reply":"2025-11-16T12:05:23.078849Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ===============================================================\n# 10. CROSS-VALIDATION FUNCTION\n# ===============================================================\ndef rmse_cv(model):\n    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n    rmse = np.sqrt(-cross_val_score(model, X_scaled, y, scoring=\"neg_mean_squared_error\", cv=kf))\n    return rmse\n\nprint(\"Lasso CV RMSE:\", rmse_cv(lasso).mean())\nprint(\"Ridge CV RMSE:\", rmse_cv(ridge).mean())\nprint(\"ElasticNet CV RMSE:\", rmse_cv(elastic).mean())\nprint(\"Stacking CV RMSE:\", rmse_cv(stack_model).mean())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T12:07:31.931667Z","iopub.execute_input":"2025-11-16T12:07:31.932005Z","iopub.status.idle":"2025-11-16T12:09:32.266824Z","shell.execute_reply.started":"2025-11-16T12:07:31.931982Z","shell.execute_reply":"2025-11-16T12:09:32.265844Z"}},"outputs":[{"name":"stdout","text":"Lasso CV RMSE: 0.11646228969343413\nRidge CV RMSE: 0.11980750154010342\nElasticNet CV RMSE: 0.11826105982459294\nStacking CV RMSE: 0.11604062779739584\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ===============================================================\n# 11. TRAIN FINAL STACKING MODEL\n# ===============================================================\nstack_model.fit(X_scaled, y)\npreds = stack_model.predict(X_test_scaled)\n\n# Reverse the log-transform\nfinal_preds = np.expm1(preds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T12:09:40.809292Z","iopub.execute_input":"2025-11-16T12:09:40.809652Z","iopub.status.idle":"2025-11-16T12:09:54.254802Z","shell.execute_reply.started":"2025-11-16T12:09:40.809609Z","shell.execute_reply":"2025-11-16T12:09:54.253934Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ===============================================================\n# 12. CREATE SUBMISSION FILE\n# ===============================================================\nsubmission = pd.DataFrame({\n    \"Id\": test_ids,\n    \"SalePrice\": final_preds\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T12:10:17.447979Z","iopub.execute_input":"2025-11-16T12:10:17.448318Z","iopub.status.idle":"2025-11-16T12:10:17.469813Z","shell.execute_reply.started":"2025-11-16T12:10:17.448295Z","shell.execute_reply":"2025-11-16T12:10:17.468657Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"     Id      SalePrice\n0  1461  126445.078401\n1  1462  158250.625550\n2  1463  181117.351666\n3  1464  195335.897701\n4  1465  194153.964035","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>126445.078401</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>158250.625550</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>181117.351666</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>195335.897701</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>194153.964035</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12}]}